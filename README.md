# Wikipedia-Crawler

Crawling wikipedia pages recursively with given categories.


*  #### We use Scrapy Framework for crawling to websites. So for to use repo succesfully first you need to install dependecies,

 #### Start by installing pip packages;
> <strong>$</strong> ` pip install -r requirements.txt `

 #### To install Scrapy on Ubuntu (or Ubuntu-based) systems, you need to install these dependencies also:
> <strong>$</strong> ` sudo apt-get install python3 python3-dev python3-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev `

</br>

### <strong>Basic Usage</strong> :
Edit CategoryCrawler/category_crawler.py. In line 14, edit url list. Add your own categorie url's.

Then start script in main directory of project.
> <strong>$</strong> ` python script.py`



<!--- 

> <strong>$</strong> ` cd museum_crawler `
> 
> <strong>$</strong> ` scrapy crawl CategoryCrawler --nolog `

--->
